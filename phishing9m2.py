# -*- coding: utf-8 -*-
"""Phishing9M2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1caw1CZ3OExIG5VFE9Zm5B6rkMZhRy9Gd
"""

!pip install nltk
!pip install python-Levenshtein

import re
from typing import Set
import sqlite3
import pandas as pd
import nltk
from nltk.corpus import words, stopwords
from Levenshtein import distance as levenshtein_distance

# Step 1: Import libraries and download NLTK resources
nltk.download('words')
nltk.download('stopwords')

# Step 2: Initialize SQLite database
def init_db(db_name: str = "phishing_database.db") -> sqlite3.Connection:
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            v1 TEXT NOT NULL,
            v2 TEXT NOT NULL
        )
    ''')
    conn.commit()
    return conn

# Step 3: Load CSV dataset and populate the database
def populate_from_csv(conn: sqlite3.Connection, csv_path: str = "phishing_dataset.csv", encoding: str = "utf-8"):
    try:
        # Read the CSV file with specified encoding
        df = pd.read_csv(csv_path, encoding=encoding)
    except UnicodeDecodeError:
        # If UTF-8 fails, try 'latin-1' as a fallback
        print(f"UTF-8 encoding failed. Trying 'latin-1' encoding...")
        df = pd.read_csv(csv_path, encoding='latin-1')
    except Exception as e:
        print(f"Error reading CSV file: {e}")
        raise

    if 'v1' not in df.columns or 'v2' not in df.columns:
        raise ValueError("CSV must contain 'v1' (label) and 'v2' (message) columns.")

    data_to_insert = [(row['v1'], str(row['v2'])) for _, row in df.iterrows() if pd.notna(row['v2'])]
    cursor = conn.cursor()
    cursor.execute("DELETE FROM messages")  # Clear the table to start fresh
    cursor.executemany("INSERT INTO messages (v1, v2) VALUES (?, ?)", data_to_insert)
    conn.commit()

# Step 4: Load known phishing words
def load_known_words(conn: sqlite3.Connection) -> Set[str]:
    cursor = conn.cursor()
    cursor.execute("SELECT v2 FROM messages WHERE v1 = 'spam'")
    spam_messages = [row[0] for row in cursor.fetchall()]
    known_words = set()
    for msg in spam_messages:
        if isinstance(msg, str):
            words = re.findall(r'\b\w+\b', msg.lower())
            known_words.update(words)
    return known_words

# Step 5: Load common English words
def load_common_words() -> Set[str]:
    common_words = set(stopwords.words('english'))
    common_words.update(words.words()[:5000])
    return {word.lower() for word in common_words}

# Step 6: Define phishing word detection
def is_phishing_word(word: str, known_words: Set[str], common_words: Set[str]) -> bool:
    word_lower = word.lower()
    if word_lower in known_words or word_lower in common_words:
        return False
    score = 0
    phishing_patterns = [
        (r"login|passw[0o]rd|verif[y|i]|acc[0o]unt", 3),
        (r"[a-zA-Z]*[0-1][a-zA-Z]*", 2),
        (r"free|urgent|click|win|prize", 2),
        (r"bank|pay|secure|update", 1),
    ]
    for pattern, points in phishing_patterns:
        if re.match(pattern, word_lower):
            score += points
    if any(levenshtein_distance(word_lower, common) <= 2 for common in common_words if len(common) > 3):
        score += 2
    if re.search(r"(com|org|net|http|www|\.|\@)", word_lower):
        score += 3
    if any(c in "0o1il" for c in word_lower):
        score += 2
    return score >= 3

# Step 7: Define database update function
def update_database(conn: sqlite3.Connection, word: str):
    cursor = conn.cursor()
    cursor.execute("INSERT INTO messages (v1, v2) VALUES (?, ?)", ("spam", word))
    conn.commit()

# Step 8: Define message processing function
def process_message(message: str, conn: sqlite3.Connection, known_words: Set[str], common_words: Set[str]):
    words = re.findall(r'\b\w+\b', message)
    for word in words:
        if is_phishing_word(word, known_words, common_words):
            print(f"New phishing word detected: {word}")
            update_database(conn, word)
            known_words.add(word.lower())
        else:
            print(f"Skipping: {word} (common word or already known)")

# Step 9: Execute the main workflow
def main():
    # Initialize the database
    conn = init_db()

    # Load the dataset into the database
    populate_from_csv(conn, "phishing_dataset.csv")
    print("Dataset loaded into database successfully.")

    # Load known phishing words and common words
    known_words = load_known_words(conn)
    print(f"Loaded {len(known_words)} known phishing words.")
    common_words = load_common_words()
    print(f"Loaded {len(common_words)} common words.")

    # Process new messages
    new_messages = [
        "Please verify your acc0unt with passw0rd at loginpage.com urgent",
        "Cl1ck here to w1n a free prize from bankofamer1ca",
        "Update your paym3nt info at secure-login.net"
    ]

    for msg in new_messages:
        print(f"\nProcessing: {msg}")
        process_message(msg, conn, known_words, common_words)

    # Close the database connection
    conn.close()
    print("Database connection closed.")

if __name__ == "__main__":
    main()

